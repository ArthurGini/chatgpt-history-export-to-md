{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Playground\n",
    "\n",
    "You've probably noticed this project lacks a unit testing set-up. Honestly, I found unit testing tricky for this and felt visual inspections of outputs, like markdowns or visualizations, were generally more trustworthy.\n",
    "\n",
    "But I get the worry of accidentally breaking things when contributing code. So, I made this notebook to help with that. It's a work in progress, aimed at letting you easily see specific outputs of interest for smoother development.\n",
    "\n",
    "Previously, my basic testing meant using a `test.py` file to generate a few markdowns and then checking them manually. Or, for a deeper look, I'd run the `main.py` and wait a while to see everything, which isn't quick on my laptop.\n",
    "\n",
    "This notebook aims to streamline that process, letting you test and inspect targeted parts of the output without the fear of breaking things.\n",
    "\n",
    "Good examples to inspect include:\n",
    "\n",
    "- Conversations with multiple branches, e.g., prompt edits, re-submissions, to see message order and dynamic linking like `[child ⬇️](#id-string)`.\n",
    "- Chats involving code interpreter.\n",
    "- Interactions with plugins and their textual outputs.\n",
    "- Chats with images, links, etc.\n",
    "- Sessions spanning different models, like starting with gpt-4 and switching to gpt-3.5.\n",
    "- Graphs, word clouds, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go ahead and add to the cells below...\n",
    "\n",
    "Currently juggling school, so my time's limited. Would appreciate any contributions to help grow this project. Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"You need to RESTART the kernel to see changes you made in the modules imported below.\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "\n",
    "# You need to RESTART the kernel to see changes you made in the modules imported below.\n",
    "from models.conversation import Conversation\n",
    "\n",
    "# create a 'data' folder in the root directory to store your personal data to test on\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "\n",
    "# assuming you put the 'conversations.json' file in the 'data' folder\n",
    "\n",
    "conversations_path = data_path / \"conversations.json\"\n",
    "\n",
    "with open(conversations_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    conversations = json.load(f)\n",
    "\n",
    "# create an 'output' folder in the root directory to store the output files\n",
    "\n",
    "output_path = Path(\"output\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def clear_output_folder():\n",
    "    for file in output_path.glob(\"*\"):\n",
    "        file.unlink()\n",
    "\n",
    "\n",
    "conversation_list = [Conversation(**c) for c in conversations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting five conversations with the highest leaf count\n",
    "\n",
    "avg_leaf_count = sum(c.leaf_count for c in conversation_list) / len(conversation_list)\n",
    "\n",
    "median_leaf_count = sorted(c.leaf_count for c in conversation_list)[\n",
    "    len(conversation_list) // 2\n",
    "]\n",
    "\n",
    "max_leaf_count = max(c.leaf_count for c in conversation_list)\n",
    "\n",
    "print(f\"Average leaf count: {avg_leaf_count}\")\n",
    "\n",
    "print(f\"Median leaf count: {median_leaf_count}\")\n",
    "\n",
    "print(f\"Max leaf count: {max_leaf_count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "convos_sorted_by_leaf_count = sorted(conversation_list, key=lambda c: c.leaf_count)\n",
    "\n",
    "for convo in convos_sorted_by_leaf_count[-5:]:\n",
    "    print(f\"id: {convo.id}\")\n",
    "    print(f\"title: {convo.title}\")\n",
    "    print(f\"leaf count: {convo.leaf_count}\")\n",
    "    convo.save_to_dir(output_path)\n",
    "    print(f\"saved to '{output_path}/'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting five conversations with the highest message count\n",
    "\n",
    "avg_message_count = sum(c.message_count for c in conversation_list) / len(\n",
    "    conversation_list\n",
    ")\n",
    "\n",
    "median_message_count = sorted(c.message_count for c in conversation_list)[\n",
    "    len(conversation_list) // 2\n",
    "]\n",
    "\n",
    "max_message_count = max(c.message_count for c in conversation_list)\n",
    "\n",
    "print(f\"Average message count: {avg_message_count}\")\n",
    "\n",
    "print(f\"Median message count: {median_message_count}\")\n",
    "\n",
    "print(f\"Max message count: {max_message_count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "convos_sorted_by_message_count = sorted(\n",
    "    conversation_list, key=lambda c: c.message_count\n",
    ")\n",
    "\n",
    "for convo in convos_sorted_by_message_count[-5:]:\n",
    "    print(f\"id: {convo.id}\")\n",
    "    print(f\"title: {convo.title}\")\n",
    "    print(f\"message count: {convo.message_count}\")\n",
    "    convo.save_to_dir(output_path)\n",
    "    print(f\"saved to '{output_path}/'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting five conversations with the most content types\n",
    "\n",
    "avg_content_type_count = sum(len(c.content_types) for c in conversation_list) / len(\n",
    "    conversation_list\n",
    ")\n",
    "\n",
    "median_content_type_count = sorted(len(c.content_types) for c in conversation_list)[\n",
    "    len(conversation_list) // 2\n",
    "]\n",
    "\n",
    "max_content_type_count = max(len(c.content_types) for c in conversation_list)\n",
    "\n",
    "print(f\"Average content type count: {avg_content_type_count}\")\n",
    "\n",
    "print(f\"Median content type count: {median_content_type_count}\")\n",
    "\n",
    "print(f\"Max content type count: {max_content_type_count}\")\n",
    "\n",
    "print()\n",
    "\n",
    "convos_sorted_by_content_type_count = sorted(\n",
    "    conversation_list, key=lambda c: len(c.content_types)\n",
    ")\n",
    "\n",
    "for convo in convos_sorted_by_content_type_count[-5:]:\n",
    "    print(f\"id: {convo.id}\")\n",
    "    print(f\"title: {convo.title}\")\n",
    "    print(f\"content types: {convo.content_types}\")\n",
    "    convo.save_to_dir(output_path)\n",
    "    print(f\"saved to '{output_path}/'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
