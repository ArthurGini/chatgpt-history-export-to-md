{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Playground\n",
    "\n",
    "You've probably noticed this project lacks a unit testing set-up. Honestly, I found unit testing tricky for this and felt visual inspections of outputs, like markdowns or visualizations, were generally more trustworthy.\n",
    "\n",
    "But I get the worry of accidentally breaking things when contributing code. So, I made this notebook to help with that. It's a work in progress, aimed at letting you easily see specific outputs of interest for smoother development.\n",
    "\n",
    "Previously, my basic testing meant using a `test.py` file to generate a few markdowns and then checking them manually. Or, for a deeper look, I'd run the `cli.py` and wait a while to see everything, which isn't quick on my laptop.\n",
    "\n",
    "This notebook aims to streamline that process, letting you test and inspect targeted parts of the output without the fear of breaking things.\n",
    "\n",
    "**Before you begin, it's recommended that you put the `conversations.json` file close by, like in a `./data/` folder.**\n",
    "\n",
    "**Make sure to restart the kernel and clear all outputs before committing changes, to ensure personal data isn't accidentally included.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Playground for testing and debugging.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Callable\n",
    "\n",
    "from controllers.file_system import conversation_set_from_json, save_conversation\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from models.conversation import Conversation\n",
    "    from models.conversation_set import ConversationSet\n",
    "\n",
    "conversations_path: Path = Path(\"data\") / \"conversations.json\"  # adjust path if needed\n",
    "output_path = Path(\"output\")\n",
    "Path(\"output\").mkdir(exist_ok=True)\n",
    "\n",
    "conversation_set: ConversationSet = conversation_set_from_json(\n",
    "    json_filepath=conversations_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_output() -> None:\n",
    "    \"\"\"Clear output folder.\"\"\"\n",
    "    for file in output_path.glob(pattern=\"*\"):\n",
    "        file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()  # run this whenever you want to clear the output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to get statistics and print conversations based on a criteria\n",
    "def get_top_convos(\n",
    "    attr_func: Callable[[Conversation], int],\n",
    "    description: str,\n",
    "    count: int = 5,\n",
    ") -> None:\n",
    "    \"\"\"Get statistics and save top conversations based on a criteria.\"\"\"\n",
    "    stats: list[int] = [attr_func(c) for c in conversation_set.conversation_list]\n",
    "    avg_stat: float = sum(stats) / len(stats)\n",
    "    median_stat: int = sorted(stats)[len(stats) // 2]\n",
    "    max_stat: int = max(stats)\n",
    "\n",
    "    print(\n",
    "        f\"Average {description}: {avg_stat}\\n\"\n",
    "        f\"Median {description}: {median_stat}\\n\"\n",
    "        f\"Max {description}: {max_stat}\\n\",\n",
    "    )\n",
    "\n",
    "    convos_sorted_by_attr: list[Conversation] = sorted(\n",
    "        conversation_set.conversation_list,\n",
    "        key=attr_func,\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    for convo in convos_sorted_by_attr[:count]:\n",
    "        print(\n",
    "            f\"id: {convo.id}\\n\"\n",
    "            f\"title: {convo.title}\\n\"\n",
    "            f\"{description}: {attr_func(convo)}\\n\",\n",
    "        )\n",
    "        file_path: Path = output_path / f\"{convo.sanitized_title()}.md\"\n",
    "        save_conversation(conversation=convo, filepath=file_path)\n",
    "        print(f\"saved to '{file_path.resolve()}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(attr_func=lambda c: c.leaf_count(), description=\"leaf count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(attr_func=lambda c: c.message_count(), description=\"message count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(\n",
    "    attr_func=lambda c: len(c.content_types()),\n",
    "    description=\"content type count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(attr_func=lambda c: len(c.used_plugins()), description=\"plugin count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "from controllers.data_analysis import wordcloud_from_conversation_set\n",
    "from utils.utils import get_colormap_names, get_font_names\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from datetime import datetime\n",
    "\n",
    "    from PIL.Image import Image\n",
    "\n",
    "weeks_dict: dict[datetime, ConversationSet] = conversation_set.grouped_by_week()\n",
    "\n",
    "week: datetime = choice(seq=list(weeks_dict.keys()))\n",
    "\n",
    "sample_conv_set: ConversationSet = weeks_dict[week]\n",
    "\n",
    "font_name: str = choice(seq=get_font_names())\n",
    "\n",
    "font_path: str = f\"assets/fonts/{font_name}.ttf\"\n",
    "\n",
    "colormap: str = choice(seq=get_colormap_names())\n",
    "\n",
    "\n",
    "img: Image = wordcloud_from_conversation_set(\n",
    "    conv_set=sample_conv_set,\n",
    "    font_path=font_path,\n",
    "    colormap=colormap,\n",
    ")\n",
    "\n",
    "print(f\"font: {font_name}\\ncolormap: {colormap}\\n\")\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllers.data_analysis import weekwise_graph_from_conversation_set\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from matplotlib.figure import Figure\n",
    "\n",
    "\n",
    "fig: Figure = weekwise_graph_from_conversation_set(conv_set=sample_conv_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
