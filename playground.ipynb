{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Playground\n",
    "\n",
    "You've probably noticed this project lacks a unit testing set-up. Honestly, I found unit testing tricky for this and felt visual inspections of outputs, like markdowns or visualizations, were generally more trustworthy.\n",
    "\n",
    "But I get the worry of accidentally breaking things when contributing code. So, I made this notebook to help with that. It's a work in progress, aimed at letting you easily see specific outputs of interest for smoother development.\n",
    "\n",
    "Previously, my basic testing meant using a `test.py` file to generate a few markdowns and then checking them manually. Or, for a deeper look, I'd run the `cli.py` and wait a while to see everything, which isn't quick on my laptop.\n",
    "\n",
    "This notebook aims to streamline that process, letting you test and inspect targeted parts of the output without the fear of breaking things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you begin, it's recommended that you put the `conversations.json` file close by, like in a `./data/` folder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure to restart the kernel and clear all outputs before committing changes, to ensure personal data isn't accidentally included.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import controllers.file_system as fs\n",
    "from models.conversation import Conversation\n",
    "from models.conversation_set import ConversationSet\n",
    "\n",
    "# Paths\n",
    "conversations_path: Path = Path(\"data\") / \"conversations.json\"  # adjust path if needed\n",
    "output_path = Path(\"output\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Load conversations\n",
    "with open(file=conversations_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    conversations = json.load(fp=f)\n",
    "\n",
    "conversation_set = ConversationSet(conversations=conversations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_output() -> None:\n",
    "    \"\"\"Clear output folder\"\"\"\n",
    "    for file in output_path.glob(pattern=\"*\"):\n",
    "        file.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()  # run this whenever you want to clear the output folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to get statistics and print conversations based on a criteria\n",
    "def get_top_convos(\n",
    "    attr_func: Callable[[Conversation], int], description: str, count: int = 5\n",
    ") -> None:\n",
    "    \"\"\"Get statistics and save top conversations based on a criteria\"\"\"\n",
    "\n",
    "    stats: list[int] = [attr_func(c) for c in conversation_set.conversation_list]\n",
    "    avg_stat: float = sum(stats) / len(stats)\n",
    "    median_stat: int = sorted(stats)[len(stats) // 2]\n",
    "    max_stat: int = max(stats)\n",
    "\n",
    "    print(\n",
    "        f\"Average {description}: {avg_stat}\\n\"\n",
    "        f\"Median {description}: {median_stat}\\n\"\n",
    "        f\"Max {description}: {max_stat}\\n\"\n",
    "    )\n",
    "\n",
    "    convos_sorted_by_attr: list[Conversation] = sorted(\n",
    "        conversation_set.conversation_list, key=attr_func, reverse=True\n",
    "    )\n",
    "\n",
    "    for convo in convos_sorted_by_attr[:count]:\n",
    "        print(\n",
    "            f\"id: {convo.id}\\n\"\n",
    "            f\"title: {convo.title}\\n\"\n",
    "            f\"{description}: {attr_func(convo)}\\n\"\n",
    "        )\n",
    "        file_path: Path = output_path / f\"{convo.sanitized_title()}.md\"\n",
    "        fs.save_conversation_to_file(conversation=convo, filepath=file_path)\n",
    "        print(f\"saved to '{file_path.resolve()}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(attr_func=lambda c: c.leaf_count(), description=\"leaf count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(attr_func=lambda c: c.message_count(), description=\"message count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(\n",
    "    attr_func=lambda c: len(c.content_types()), description=\"content type count\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_convos(attr_func=lambda c: len(c.used_plugins()), description=\"plugin count\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from random import choice\n",
    "\n",
    "from utils.utils import get_colormap_names, get_font_names\n",
    "\n",
    "weeks_dict: dict[datetime, ConversationSet] = conversation_set.grouped_by_week()\n",
    "\n",
    "week: datetime = choice(seq=list(weeks_dict.keys()))\n",
    "\n",
    "sample_conv_set: ConversationSet = weeks_dict[week]\n",
    "\n",
    "font_name: str = choice(seq=get_font_names())\n",
    "\n",
    "font_path: str = f\"assets/fonts/{font_name}.ttf\"\n",
    "\n",
    "colormap: str = choice(seq=get_colormap_names())\n",
    "\n",
    "\n",
    "fs.save_wordcloud_from_conversation_set(\n",
    "    conv_set=sample_conv_set,\n",
    "    dir_path=output_path,\n",
    "    time_period=(week, \"week\"),\n",
    "    font_path=font_path,\n",
    "    colormap=colormap,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"font: {font_name}\\n\"\n",
    "    f\"colormap: {colormap}\\n\"\n",
    "    f\"week: {week.strftime('%Y week %W')}\\n\"\n",
    "    f\"saved to '{output_path.resolve()}'\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
